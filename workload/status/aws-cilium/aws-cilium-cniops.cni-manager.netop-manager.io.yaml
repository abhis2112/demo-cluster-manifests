apiVersion: v1
data:
  cniops.cni-manager.netop-manager.io.yaml: |
    "name:unmanaged, ns:netop-manager-system, status:{\"cniStatus\":{\"Cilium\":\"Defaulted container \\\"cilium-agent\\\" out of: cilium-agent, mount-cgroup (init), wait-for-node-init (init), clean-cilium-state (init)\\nUnable to use a TTY - input is not a terminal or the right kind of file\\nDefaulted container \\\"cilium-agent\\\" out of: cilium-agent, mount-cgroup (init), wait-for-node-init (init), clean-cilium-state (init)\\nUnable to use a TTY - input is not a terminal or the right kind of file\\nKVStore:                Ok   Disabled\\nKubernetes:             Ok   1.21+ (v1.21.9-eks-0d102a7) [linux/amd64]\\nKubernetes APIs:        [\\\"cilium/v2::CiliumClusterwideNetworkPolicy\\\", \\\"cilium/v2::CiliumEndpoint\\\", \\\"cilium/v2::CiliumNetworkPolicy\\\", \\\"cilium/v2::CiliumNode\\\", \\\"core/v1::Namespace\\\", \\\"core/v1::Node\\\", \\\"core/v1::Pods\\\", \\\"core/v1::Service\\\", \\\"discovery/v1::EndpointSlice\\\", \\\"networking.k8s.io/v1::NetworkPolicy\\\"]\\nKubeProxyReplacement:   Disabled   \\nHost firewall:          Disabled\\nCilium:                 Ok   1.11.2 (v1.11.2-17b0dbd)\\nNodeMonitor:            Listening for events on 2 CPUs with 64x4096 of shared memory\\nCilium health daemon:   Ok   \\nIPAM:                   IPv4: 6/15 allocated, \\nBandwidthManager:       Disabled\\nHost Routing:           Legacy\\nMasquerading:           IPTables [IPv4: Enabled, IPv6: Disabled]\\nController Status:      38/38 healthy\\nProxy Status:           OK, ip 192.168.48.249, 0 redirects active on ports 10000-20000\\nHubble:                 Ok   Current/Max Flows: 4095/4095 (100.00%), Flows/s: 3.22   Metrics: Disabled\\nEncryption:             Disabled\\nCluster health:         2/2 reachable   (2022-05-30T07:07:50Z)\\nKVStore:                Ok   Disabled\\nKubernetes:             Ok   1.21+ (v1.21.9-eks-0d102a7) [linux/amd64]\\nKubernetes APIs:        [\\\"cilium/v2::CiliumClusterwideNetworkPolicy\\\", \\\"cilium/v2::CiliumEndpoint\\\", \\\"cilium/v2::CiliumNetworkPolicy\\\", \\\"cilium/v2::CiliumNode\\\", \\\"core/v1::Namespace\\\", \\\"core/v1::Node\\\", \\\"core/v1::Pods\\\", \\\"core/v1::Service\\\", \\\"discovery/v1::EndpointSlice\\\", \\\"networking.k8s.io/v1::NetworkPolicy\\\"]\\nKubeProxyReplacement:   Disabled   \\nHost firewall:          Disabled\\nCilium:                 Ok   1.11.2 (v1.11.2-17b0dbd)\\nNodeMonitor:            Listening for events on 2 CPUs with 64x4096 of shared memory\\nCilium health daemon:   Ok   \\nIPAM:                   IPv4: 3/11 allocated, \\nBandwidthManager:       Disabled\\nHost Routing:           Legacy\\nMasquerading:           IPTables [IPv4: Enabled, IPv6: Disabled]\\nController Status:      24/24 healthy\\nProxy Status:           OK, ip 192.168.31.57, 0 redirects active on ports 10000-20000\\nHubble:                 Ok   Current/Max Flows: 4095/4095 (100.00%), Flows/s: 0.34   Metrics: Disabled\\nEncryption:             Disabled\\nCluster health:         2/2 reachable   (2022-05-30T07:07:51Z)\\n\"},\"cniType\":\"cko-cni-cilium\",\"internalState\":\"Monitoring\",\"observedGeneration\":4,\"operatorStatus\":\"Running\"}"
kind: ConfigMap
metadata:
  labels:
    netop-manager-resource: cniops.cni-manager.netop-manager.io
  name: aws-cilium-cniops.cni-manager.netop-manager.io
  namespace: 
